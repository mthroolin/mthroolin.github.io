<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Michael Throolin">

<title>Selected Solutions to Boos and Stefanski - Chapter 3: Likelihood-Based Tests and Confidence Regions</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/ch5.html" rel="next">
<link href="../chapters/ch2.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/ch3.html"><span class="chapter-title">Chapter 3: Likelihood-Based Tests and Confidence Regions</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Selected Solutions to Boos and Stefanski</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/ch1.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 1: Roles of Modeling in Statistical Inference</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/ch2.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 2: Likelihood Construction and Estimation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/ch3.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">Chapter 3: Likelihood-Based Tests and Confidence Regions</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/ch5.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 5: Large Sample Theory: The Basics</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/ch6.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 6: Large Sample Results for Likelihood-Based Methods</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/ch7.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 7: M-Estimation (Estimating Equations)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/ch8.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 8: Hypothesis Tests under Misspecification and Relaxed Assumptions</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#section" id="toc-section" class="nav-link active" data-scroll-target="#section">3.6</a></li>
  <li><a href="#section-1" id="toc-section-1" class="nav-link" data-scroll-target="#section-1">3.8</a>
  <ul class="collapse">
  <li><a href="#a." id="toc-a." class="nav-link" data-scroll-target="#a.">a.</a></li>
  </ul></li>
  <li><a href="#section-2" id="toc-section-2" class="nav-link" data-scroll-target="#section-2">3.9</a></li>
  <li><a href="#section-3" id="toc-section-3" class="nav-link" data-scroll-target="#section-3">3.12</a></li>
  <li><a href="#section-4" id="toc-section-4" class="nav-link" data-scroll-target="#section-4">3.16</a></li>
  <li><a href="#section-5" id="toc-section-5" class="nav-link" data-scroll-target="#section-5">3.18</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-title">Chapter 3: Likelihood-Based Tests and Confidence Regions</span></h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Michael Throolin </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<section id="section" class="level2">
<h2 class="anchored" data-anchor-id="section">3.6</h2>
<p>Assume that <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(Y_2\)</span> are independent with respective geometric probability mass functions, <span class="math display">\[f(y;p_i) = p_i(1-p_i)^{y-1}~~~~y=0,1,\dots~~~~ 0 \leq p_i \leq 1, ~~i=1,2.\]</span> Recall that the mean and variance of a geometric random variable with parameter <span class="math inline">\(p\)</span> are <span class="math inline">\(1/p\)</span> and <span class="math inline">\((1-p)/p^2\)</span>, respectively. For <span class="math inline">\(H_0: p_1=p_2\)</span> versus <span class="math inline">\(H_a: p_1 \neq p_2\)</span> show that the score statistic is <span class="math display">\[T_S=\frac{\overset \sim p ^2}{2(1- \overset \sim p)}(Y_1-Y_2)^2, ~~~where~\overset \sim p = \frac 2 {Y_1+Y_2}\]</span></p>
<p>Solution:</p>
<p><span class="math display">\[\begin{aligned}
\boldsymbol \theta &amp;= \begin{pmatrix} p_1 \\p_2 \end{pmatrix}, ~~~ h(\boldsymbol \theta) =p_1-p_2 = 0 \\
\mathcal L(\boldsymbol \theta) &amp;= p_1(1-p_1)^{y_1-1}p_2(1-p_2)^{y_2-1},~~~~ H(\boldsymbol \theta) = \begin{bmatrix} 1 &amp; -1 \end{bmatrix}
\\
\mathcal \ell(\boldsymbol \theta) &amp;= \log p_1 + (y_1-1)\log(1-p_1) +\log p_2+ (y_2-1)\log(1-p_2)
\end{aligned}
\]</span> <span class="math display">\[\begin{aligned}
S(\boldsymbol \theta) &amp;= \begin{pmatrix} \frac 1 {p_1}- \frac{y_1-1}{1-p_1} \\ \frac 1 {p_2}- \frac{y_2-1}{1-p_2} \end{pmatrix} \\
I_T(\boldsymbol \theta) &amp;= -E\begin{pmatrix} \frac {-1} {p_1^2}- \frac{y_1-1}{(1-p_1)^2} &amp; 0 \\ 0&amp; \frac {-1} {p_2^2}- \frac{y_2-1}{(1-p_2)^2} \end{pmatrix} =-\begin{pmatrix} \frac {-1} {p_1^2}- \frac{\frac{1}{p_1}-1}{(1-p_1)^2} &amp; 0 \\ 0&amp; \frac {-1} {p_2^2}- \frac{\frac{1}{p_2}-1}{(1-p_2)^2} \end{pmatrix} \\
&amp;=-\begin{pmatrix} \frac {-(1-p_1)^2-p_1+p_1^2}{p_1^2(1-p_1)^2}&amp; 0 \\ 0&amp; \frac {-(1-p_2)^2-p_2+p_2^2}{p_2^2(1-p_2)^2} \end{pmatrix}=-\begin{pmatrix} \frac {-1+2p_1-p_1^2-p_1+p_1^2}{p_1^2(1-p_1)^2}&amp; 0 \\ 0&amp; \frac {-1+2p_2 - p_2^2-p_2+p_2^2}{p_2^2(1-p_2)^2} \end{pmatrix} \\
&amp;=-\begin{pmatrix} \frac {p_1-1}{p_1^2(1-p_1)^2}&amp; 0 \\ 0&amp; \frac {p_2-1}{p_2^2(1-p_2)^2} \end{pmatrix}
=\begin{pmatrix} \frac {1}{p_1^2(1-p_1)}&amp; 0 \\ 0&amp; \frac {1}{p_2^2(1-p_2)} \end{pmatrix} \\
I_T(\boldsymbol \theta)^{-1} &amp;=  \begin{pmatrix} p_1^2(1-p_1)&amp; 0 \\ 0&amp; p_2^2(1-p_2) \end{pmatrix}
\end{aligned}\]</span></p>
<p>Using the Lagrange multiplier method, <span class="math display">\[\begin{aligned}
maximize \{\ell(p)  -\lambda h(\theta)\}
&amp; = \log p_1 + (y_1-1)\log(1-p_1) +\log p_2+ (y_2-1)\log(1-p_2) + \lambda p_1 - \lambda p_2\\
p_1 &amp;= p_2  = p\\
0 &amp;= \frac{1} {p} -\frac{y_1-1}{1-p} + \lambda \implies \lambda = -\frac{1} {p} +\frac{y_1-1}{1-p}\\
0 &amp;= \frac{1} {p} -\frac{y_2-1}{1-p} -\lambda \implies \lambda = \frac{1} {p} -\frac{y_2-1}{1-p} \\
\implies 0&amp;= \frac{2} {p} -\frac{y_2-1+y_1-1}{1-p}\\
&amp;= 2-2p +2p -p(y_1+y_2) \\
\implies \overset \sim p &amp;= \frac 2 {y_1+y_2},~~~ \hat \lambda_{RMLE} = \frac{1} {\overset \sim p} -\frac{y_2-1}{1-\overset \sim p}\\
&amp; \hat \lambda_{RMLE} =  \frac{1- \overset \sim p - \overset \sim p y_2+ \overset \sim p}{\overset \sim p (1-\overset \sim p)}=  \frac{1 - \frac {2y_2} {y_1+y_2}}{\overset \sim p (1-\overset \sim p)} \\
&amp;\hat \lambda_{RMLE}=  \frac{\frac {y_1-y_2} {y_1+y_2}}{\overset \sim p (1-\overset \sim p)}=\frac {(y_1-y_2) \overset \sim p /2}{\overset \sim p (1-\overset \sim p)}\\
&amp;\hat \lambda_{RMLE}=  \frac{y_1-y_2}{2 (1-\overset \sim p)}
\end{aligned}\]</span></p>
<p><span class="math display">\[\begin{aligned}
T_S &amp;= \hat \lambda_{RMLE}^T H(\hat \theta_{RMLE})I_T^{-1}(\hat \theta_{RMLE})  H(\hat \theta_{RMLE})^T\hat \lambda_{RMLE}^T \\
&amp;= \left(\frac{y_1-y_2}{2 (1-\overset \sim p)}\right)^2  \begin{pmatrix} 1 &amp; -1 \end{pmatrix} \begin{pmatrix} \overset \sim p^2(1-\overset \sim p)&amp; 0 \\ 0&amp;\overset \sim p^2(1-\overset \sim p) \end{pmatrix} \begin{pmatrix} 1 \\ -1 \end{pmatrix} \\
&amp;= \left(\frac{y_1-y_2}{2 (1-\overset \sim p)}\right)^2  2 (\overset \sim p^2(1-\overset \sim p)) \\
&amp;= \frac{\overset \sim p^2}{2 (1-\overset \sim p)}(y_1-y_2)^2
\end{aligned}\]</span></p>
</section>
<section id="section-1" class="level2">
<h2 class="anchored" data-anchor-id="section-1">3.8</h2>
<p>Suppose that <span class="math inline">\(Y_1,\dots, Y_{n_1}\)</span> are iid from a <span class="math inline">\(N(\mu_1,\sigma^2)\)</span> distribution, <span class="math inline">\(X_1,\dots,X_{n_2}\)</span> are iid from a <span class="math inline">\(N(\mu_2,\sigma^2)\)</span> distribution, the samples are independent of each other, and we desire to test <span class="math inline">\(H_0:\mu_1=\mu_2\)</span>.</p>
<section id="a." class="level3">
<h3 class="anchored" data-anchor-id="a.">a.</h3>
<p>Derive the Wald and score tests and express them as a function of the square of the usual two-sample pooled t . Also, show that the likelihood ratio statistic is <span class="math inline">\(T_{LR} = (n_1+n_2)\log[1+t^2/(n_1+n_2-2)]\)</span>.</p>
<p>Solution:</p>
<p><span class="math display">\[\begin{aligned}
\ell (\mu_1,\mu_2,\sigma) &amp;= c-n_1\log \sigma - \frac 1 {2\sigma^2} \sum_{i=1}^{n_1}(Y_i-\mu_1)^2 +c-n_2\log \sigma - \frac 1 {2\sigma^2} \sum_{i=1}^{n_2}(X_i-\mu_2)^2\\
&amp;= 2c-(n_1+n_2)\log \sigma - \frac 1 {2\sigma^2} \sum_{i=1}^{n_1}(Y_i-\mu_1)^2 - \frac 1 {2\sigma^2} \sum_{i=1}^{n_2}(X_i-\mu_2)^2 \\
S\begin{pmatrix} \mu_1 \\ \mu_2 \\\sigma \end{pmatrix}
&amp;=\begin{pmatrix} \frac 1 {\sigma^2} \sum_{i=1}^{n_1} (Y_i-\mu_1)\\
\frac 1 {\sigma^2} \sum_{i=1}^{n_2} (X_i-\mu_2)\\
\frac{-n_1-n_2}{\sigma} +\frac 1 {\sigma^3} \sum_{i=1}^{n_1} (Y_i-\mu_1)^2 +\frac 1 {\sigma^3} \sum_{i=1}^{n_2} (X_i-\mu_2)^2 \end{pmatrix}\\
&amp;=\begin{pmatrix} \frac 1 {\sigma^2} \sum_{i=1}^{n_1} (Y_i-\mu_1)\\
\frac 1 {\sigma^2} \sum_{i=1}^{n_2} (X_i-\mu_2)\\
\frac 1 {\sigma^3} \sum_{i=1}^{n_1} [(Y_i-\mu_1)^2-\sigma^2] +\frac 1 {\sigma^3} \sum_{i=1}^{n_2} [(X_i-\mu_2)^2 - \sigma^2] \end{pmatrix}\\
I_T \begin{pmatrix} \mu_1 \\ \mu_2 \\\sigma \end{pmatrix}
&amp;= \begin{pmatrix} \frac {n_1} {\sigma^2} &amp;0&amp;0\\
0&amp;\frac {n_2} {\sigma^2} &amp; 0\\
0&amp;0&amp; \frac{n_1+n_2}{\sigma^2}\end{pmatrix},
I_T^{-1} \begin{pmatrix} \mu_1 \\ \mu_2 \\\sigma \end{pmatrix}
= \sigma^2 \begin{pmatrix} \frac {1} {n_1} &amp;0&amp;0\\
0&amp;\frac {1} {n_2} &amp; 0\\
0&amp;0&amp; \frac 1 {n_1+n_2}\end{pmatrix} \\
\mathbf h( \boldsymbol {\theta}) &amp;= \mu_1-\mu_2 ,
\mathbf H(\boldsymbol \theta) = \begin{pmatrix} 1 &amp; -1 &amp;0\end{pmatrix}, \mathbf H(\boldsymbol \theta) \mathbf {I_T^{-1}}(\boldsymbol {\theta}) \mathbf H(\boldsymbol \theta)^T= \sigma^2 \left(\frac 1 {n_1} +\frac 1 {n_2}\right)
\end{aligned}\]</span></p>
<p><span class="math display">\[\begin{aligned}
\begin{pmatrix} \frac 1 {\sigma^2} \sum_{i=1}^{n_1} (Y_i-\mu_1)\\
\frac 1 {\sigma^2} \sum_{i=1}^{n_2} (X_i-\mu_2)\\
\frac 1 {\sigma^3} \sum_{i=1}^{n_1} [(Y_i-\mu_1)^2-\sigma^2] +\frac 1 {\sigma^3} \sum_{i=1}^{n_2} [(X_i-\mu_2)^2 - \sigma^2] \end{pmatrix} &amp;= \mathbf 0 \\
\implies \hat \mu_1 = \frac 1 {n_1} \sum_{i=1}^{n_1} Y_i = \bar Y ~~,~~\hat \mu_2 = \frac 1 {n_2} \sum_{i=1}^{n_2} X_i = \bar X \\
\sum_{i=1}^{n_1} [(Y_i-\hat \mu_1)^2-\sigma^2] + \sum_{i=1}^{n_2} [(X_i-\hat \mu_2)^2 - \hat \sigma^2] = 0 \\
\sum_{i=1}^{n_1} (Y_i-\bar Y)^2 + \sum_{i=1}^{n_2} (X_i-\bar X)^2  =  (n_1+ n_2) \hat \sigma^2 \\
\implies \hat \sigma_{MLE} ^2 = \frac{\sum_{i=1}^{n_1} (Y_i-\bar Y)^2 + \sum_{i=1}^{n_2} (X_i-\bar X)^2 }{n_1+n_2}
\end{aligned}
\]</span></p>
<p>Note that <span class="math display">\[\begin{aligned}
S_p^2 &amp;= \frac{\sum_{i=1}^{n_1} (Y_i-\bar Y)^2 + \sum_{i=1}^{n_2} (X_i-\bar X)^2 }{n_1+n_2-2} \\
\implies \frac{(n_1+ n_2 -2)}{n_1+n_2}S_p^2 &amp;= \hat \sigma^2_{MLE}
\end{aligned}\]</span> <span class="math display">\[
\begin{aligned}
\implies  \sigma_{RMLE} ^2
&amp;= \frac{\sum_{i=1}^{n_1} (Y_i- \mu)^2 + \sum_{i=1}^{n_2} (X_i- \mu)^2 }{n_1+n_2}\\
&amp;= \frac{\sum_{i=1}^{n_1} (Y_i-\bar Y + \bar Y- \mu)^2 + \sum_{i=1}^{n_2} (X_i- \bar X + \bar X- \mu)^2 }{n_1+n_2}\\
&amp;= \frac{\sum_{i=1}^{n_1} (Y_i-\bar Y)^2 + 2(Y_i-\bar Y)(\bar Y- \mu) +(\bar Y- \mu)^2 + \sum_{i=1}^{n_2} (X_i-\bar X)^2 + 2(X_i-\bar X)(\bar X- \mu) +(\bar X- \mu)^2  }{n_1+n_2}\\
&amp;= \frac{\sum_{i=1}^{n_1} (Y_i-\bar Y)^2  +(\bar Y- \mu)^2 + \sum_{i=1}^{n_2} (X_i-\bar X)^2 +(\bar X- \mu)^2  }{n_1+n_2}\\
&amp;= \frac{\sum_{i=1}^{n_1} (Y_i-\bar Y)^2 + \sum_{i=1}^{n_2} (X_i-\bar X)^2 +n_1(\bar Y- \mu)^2+n_2(\bar X- \mu)^2  }{n_1+n_2}\\
&amp;= \sigma^2_{MLE}+\frac{n_1(\bar Y- \mu)^2+n_2(\bar X- \mu)^2  }{n_1+n_2}
\end{aligned}\]</span></p>
<p>Thus, the Wald Statistic is:</p>
<p><span class="math display">\[\begin{aligned}
T_W &amp;= \mathbf h( \boldsymbol {\hat \theta})^T [\mathbf H(\boldsymbol {\hat \theta}) \mathbf {I_T^{-1}}(\boldsymbol {\hat \theta}) \mathbf H(\boldsymbol {\hat \theta})^T]^{-1}\mathbf h( \boldsymbol {\hat \theta})\\
&amp;= \frac{(\bar Y- \bar X)^2}{\hat \sigma^2_{MLE} \left(\frac 1 {n_1} +\frac 1 {n_2}\right)}
\end{aligned}\]</span></p>
<p>Now, for the score function, I need to maximize <span class="math inline">\(\ell (\mu_1,\mu_2, \sigma) -\lambda(\mu_1-\mu_2)\)</span>.</p>
<p><span class="math display">\[\begin{aligned}
\mu_1- \mu_2 = 0 &amp;\implies \mu_1 = \mu_2 = \mu\\
\frac 1 {\sigma^2} \sum_{i=1}^{n_1} (Y_i-\mu) -\lambda =0&amp; \implies \lambda= \frac{1}{\sigma^2} \sum_{i=1}^{n_1} (Y_i-\mu) \\\\
\frac 1 {\sigma^2} \sum_{i=1}^{n_2} (X_i-\mu) + \frac{1}{\sigma^2} \sum_{i=1}^{n_1} (Y_i-\mu)= 0
&amp;\implies \hat \mu_{RMLE} = \frac{\sum_{i=1}^{n_2} X_i + \sum_{i=1}^{n_1} Y_i}{n_1+n_2} = \frac{n_2 \bar X + n_1 \bar Y}{n_1+n_2}
\end{aligned}\]</span></p>
<p>Simplifying <span class="math inline">\(\hat \lambda_{RMLE}\)</span>, <span class="math display">\[\begin{aligned}
\hat \lambda&amp;= \frac{1}{\sigma^2} \sum_{i=1}^{n_1} (Y_i-\mu) \\
&amp;= \frac{1}{\sigma^2} \sum_{i=1}^{n_1} (Y_i)-n_1 \left(\frac{\sum_{i=1}^{n_1} X_i + \sum_{i=1}^{n_2} Y_i}{n_1+n_2}\right) \\
&amp;= \frac{1}{\sigma^2} \left(\frac{(n_1+n_2)\sum_{i=1}^{n_1} (Y_i)-n_1 \left(\sum_{i=1}^{n_1} X_i + \sum_{i=1}^{n_2} Y_i\right)}{n_1+n_2}\right) \\
&amp;= \frac{1}{\sigma^2} \left(\frac{n_2\sum_{i=1}^{n_1} Y_i-n_1 \sum_{i=1}^{n_1} X_i}{n_1+n_2}\right) \\
&amp;= \frac{1}{\sigma^2} \left(\frac{n_1n_2}{n_1+n_2} \right)(\bar Y - \bar X)
\end{aligned}\]</span></p>
<p>The score statistic is: <span class="math display">\[\begin{aligned}
T_S &amp;= \hat \lambda_{RMLE}^T H(\hat \theta_{RMLE})I_T^{-1}(\hat \theta_{RMLE}) \hat \lambda_{RMLE}^T \\
&amp;= \left[\frac{1}{\sigma^2} \left(\frac{n_1n_2}{n_1+n_2} \right)(\bar Y - \bar X)\right]^2\sigma^2 \left(\frac 1 {n_1} +\frac 1 {n_2}\right) \\
&amp;= \frac{1}{\sigma^2} \left[\left(\frac{n_1n_2}{n_1+n_2} \right)(\bar Y - \bar X)\right]^2 \left(\frac {n_1+n_2} {n_1n_2}\right) \\
&amp;= \frac{(\bar Y - \bar X)^2 }{\sigma^2\left(\frac 1 {n_1} +\frac 1{n_2}\right)}
\end{aligned}\]</span></p>
<p>And the LRT is:</p>
<p><span class="math display">\[\begin{aligned}T_{LR} &amp;= -2 [\ell (\hat \theta_{RMLE}) - \ell(\hat \theta_{RMLE})] \\
&amp;=-2 [2c- \frac 1 2 (n_1+n_2)\log \sigma_{RMLE}^2 - \frac 1 {2\sigma_{RMLE}^2} \sum_{i=1}^{n_1}(Y_i-\mu)^2 - \frac 1 {2\sigma_{RMLE}^2} \sum_{i=1}^{n_2}(X_i-\mu)^2] \\
&amp;~~~~~~+2 [2c-\frac 1 2 (n_1+n_2)\log \sigma_{MLE}^2 - \frac 1 {2\sigma_{MLE}^2} \sum_{i=1}^{n_1}(Y_i-\mu_1)^2 - \frac 1 {2\sigma_{MLE}^2} \sum_{i=1}^{n_2}(X_i-\mu_2)^2] \\
&amp;=(n_1+n_2) \log \left(\frac{\sigma_{RMLE}^2}{\sigma_{MLE}^2} \right)\\
&amp;= (n_1+n_2) \log \left(\frac{\sigma^2_{MLE}+\frac{n_1(\bar Y- \mu)^2+n_2(\bar X- \mu)^2  }{n_1+n_2}}{\sigma_{MLE}^2} \right)\\
&amp;= (n_1+n_2) \log \left(1+\frac{\frac 1{n_1+n_2}\left(n_1(\bar Y- \frac{n_2 \bar X + n_1 \bar Y}{n_1+n_2})^2+n_2(\bar X- \frac{n_2 \bar X + n_1 \bar Y}{n_1+n_2})^2  \right)}
{\sigma^2_{MLE}} \right)\\
&amp;= (n_1+n_2) \log \left(1+\frac{\frac 1{n_1+n_2}\left(n_1(\frac{n_2 \bar Y- n_2 \bar X}{n_1+n_2})^2+n_2(\frac{n_1 \bar X - n_1 \bar Y}{n_1+n_2})^2  \right)}{\sigma_{MLE}^2 } \right)\\
&amp;= (n_1+n_2) \log \left(1+\frac{\frac 1{(n_1+n_2)^3}\left(n_1n_2^2( \bar Y- \bar X)^2+n_1^2n_2(\bar X - \bar Y)^2  \right)}{\sigma_{MLE}^2 } \right)\\
&amp;= (n_1+n_2) \log \left(1+\frac{\frac{n_1n_2}{(n_1 + n_2)^2} \left(\bar Y - \bar X\right)^2}
{\sigma_{MLE}^2 } \right)\\
&amp;= (n_1+n_2) \log \left(1+\frac{ \left(\bar Y - \bar X\right)^2}
{(n_1+n_2)\sigma_{MLE}^2 \left(\frac 1{n_1} + \frac 1 {n_2}\right)} \right)\\
&amp;= (n_1+n_2) \log \left(1+\frac{ \left(\bar Y - \bar X\right)^2}
{(n_1+n_2-2)S_p^2 \left(\frac 1{n_1} + \frac 1 {n_2}\right)} \right)\\
&amp;= (n_1+n_2) \log \left(1+\frac{t^2}{(n_1+n_2-2)} \right)
\end{aligned}
\]</span></p>
<ol start="2" type="a">
<li></li>
</ol>
<p>Let <span class="math inline">\(n_1= n_2=5\)</span>. These tests reject <span class="math inline">\(H_0\)</span> at approximate level .05 if they are larger than 3.84. Find exact expressions for <span class="math inline">\(P(T_W \geq 3.84), P(T_S \geq 3.84),\)</span> and <span class="math inline">\(P(T_{LR} \geq 3.84)\)</span> using the fact that <span class="math inline">\(t^2\)</span> has an <span class="math inline">\(F(1,n_1+n_2-2)\)</span> under <span class="math inline">\(H_0\)</span>.</p>
<p>Solution:</p>
<p><span class="math display">\[\begin{aligned}
P(T_W \geq 3.84)= P(T_S \geq 3.84) &amp;= P\left(\frac{(\bar Y- \bar X)^2}{\hat \sigma^2_{MLE} \left(\frac 1 {5} +\frac 1 {5}\right)} \geq 3.84\right) \\
&amp;= 1-\chi^2_{(1)}(3.84) \\
P(T_{LR} \geq 3.84) &amp;= P\left((5+5) \log \left(1+\frac{t^2}{(5+5-2)} \right) \geq 3.84\right) \\
&amp;= P\left(1+t^2/8  \geq \exp(0.384)\right)\\
&amp;= P\left(t^2  \geq 8(\exp(0.384)-1)\right)\\
&amp;= 1-F_{8\exp(0.384)-8}(1,8)
\end{aligned}\]</span></p>
</section>
</section>
<section id="section-2" class="level2">
<h2 class="anchored" data-anchor-id="section-2">3.9</h2>
<p>Suppose that <span class="math inline">\(Y_1,\dots, Y_n\)</span> are independently distributed as Poisson random variables with means <span class="math inline">\(\lambda_1, \dots, \lambda_n\)</span>, respectively. Thus, <span class="math inline">\(P(Y_i=y) = f(y;\lambda_i) =\frac{\lambda_i^y e^{-\lambda_i}}{y!}I(y \in \mathbb N)\)</span>. Show that the score statistic for testing <span class="math inline">\(H_0: \lambda_1 = \lambda_2 = \dots = \lambda_n=\lambda\)</span> (i.e., that the <span class="math inline">\(Y_i\)</span> ’s all have the same distribution) is given by <span class="math inline">\(T_S = \sum_{i=1}^n \frac{(Y_i-\bar Y)^2}{\bar Y}\)</span>.</p>
<p>Solution:</p>
<p><span class="math display">\[\begin{aligned}
\mathcal L(\boldsymbol \lambda) &amp;=\prod_{i=1}^n \frac{\lambda_i^{y_i} e^{-\lambda_i}}{y_i!} \\
\ell (\boldsymbol \lambda) &amp;=\sum_{i=1}^n y_i \log \lambda_i -\lambda_i -\log(y_i!) \\
S_i (\boldsymbol \lambda) &amp;= \frac {y_i} {\lambda_i}-1 \\
I_T (\boldsymbol \lambda) &amp;= diag\left(-E\left(\frac{-y_i}{\lambda_i^2}\right)\right) = diag(1/\lambda_i) \\
I_T^{-1} (\boldsymbol \lambda)&amp;= diag(\lambda_i)
\end{aligned}\]</span></p>
<p><span class="math display">\[\begin{aligned}
0 &amp;=S_i (\boldsymbol \lambda) = \frac {y_i} {\lambda_i}-1 \\
\implies \hat \lambda_{i_{MLE}} &amp;=y_i~~~,~~~~ \hat \lambda_{RMLE} =\bar y
\end{aligned}\]</span></p>
<p><span class="math display">\[\begin{aligned}
T_S &amp;= \mathbf {S(\boldsymbol{\hat \lambda}_{RMLE})^T I_T^{-1} (\boldsymbol {\hat \lambda_{RMLE}})S(\boldsymbol{\hat \lambda}_{RMLE})}\\
&amp;= \left\{\frac {Y_i} {\bar Y}-1 \right\}diag(\bar Y)\left\{\frac {Y_i} {\bar Y}-1 \right\}\\
&amp;= \sum_{i=1}^n \bar Y\left(\frac {Y_i} {\bar Y}-1 \right)^2=\sum_{i=1}^n \bar Y\left(\frac {Y_i - \bar Y} {\bar Y}\right)^2\\
&amp;= \sum_{i=1}^n \frac {(Y_i-\bar Y)^2} {\bar Y}\\
\end{aligned}\]</span></p>
</section>
<section id="section-3" class="level2">
<h2 class="anchored" data-anchor-id="section-3">3.12</h2>
<p>Show that the <span class="math inline">\(T_W\)</span>, <span class="math inline">\(T_S\)</span> and <span class="math inline">\(T_{LR}\)</span> statistics defined in Example 3.2 (p.&nbsp;129) are asymptotically equivalent under <span class="math inline">\(H_0\)</span> by showing their differences converge to 0 in probability.</p>
<p>Solution:</p>
<p><span class="math display">\[\begin{aligned}
\ell (\hat p) &amp;= \ell(p_0) + \ell'(p_0)(\hat p - p_0) +\frac 1 2 \ell^{2}(p_0)(\hat p - p_0)^2+ \frac 1 6 \ell^3 (p^*)(\hat p - p_o)^3 \\
\implies T_{LR} &amp;=-2\left[\ell (\hat p_0) - \ell (\hat p) \right] \\
&amp;=-2\left[\ell (\hat p_0) - \ell(p_0) - \ell'(p_0)(\hat p - p_0) -\frac 1 2 \ell^{2}(p_0)(\hat p - p_0)^2- \frac 1 6 \ell^3 (p^*)(\hat p - p_o)^3 \right] \\
&amp;=2\left[S(p_0)(\hat p - p_0) -\frac 1 2 I_T(p_0)(\hat p - p_0)^2+ \frac 1 6 \ell^3 (p^*)(\hat p - p_o)^3 \right] \\
&amp;=2\left[\frac{n \hat p - n p_0}{p_0 (1-p_0)}(\hat p -p_0)-\frac 1 2 \left(\frac{n \hat p}{p_0^2}+ \frac{n-n\hat p}{(1-p_0)^2}\right)(\hat p - p_0)^2+ \frac 1 6 \ell^3 (p^*)(\hat p - p_o)^3 \right] \\
&amp;=n (\hat p -p_0)^2\left[\frac{2}{p_0 (1-p_0)}-\left(\frac{\hat p}{p_0^2}+ \frac{1-\hat p}{(1-p_0)^2}\right)+ \frac 1 {3n} \ell^3 (p^*)(\hat p - p_o) \right] \\
\implies T_W- T_{LR} &amp;= \frac{n(\hat p- p_0)^2}{\hat p (1-\hat p)} -n (\hat p -p_0)^2\left[\frac{2}{p_0 (1-p_0)}-\left(\frac{\hat p}{p_0^2}+ \frac{1-\hat p}{(1-p_0)^2}\right)+ \frac 1 {3n} \ell^3 (p^*)(\hat p - p_o) \right] \\
&amp;= n(\hat p- p_0)^2\left[\frac 1 {\hat p (1-\hat p)}-\frac{2}{p_0 (1-p_0)}+\frac{\hat p}{p_0^2}+ \frac{1-\hat p}{(1-p_0)^2}+ \frac 1 {3n} \ell^3 (p^*)(\hat p - p_o) \right]
\end{aligned}\]</span></p>
<p>Note that <span class="math inline">\(n(\hat p- p_0)^2 \overset d \to \chi^2_{something}\)</span> and,</p>
<p><span class="math display">\[\begin{aligned}
&amp;\lim_{n \to \infty}\left[\frac 1 {\hat p (1-\hat p)}-\frac{2}{p_0 (1-p_0)}+\frac{\hat p}{p_0^2}+ \frac{1-\hat p}{(1-p_0)^2}+ \frac 1 {3n} \ell^3 (p^*)(\hat p - p_0) \right] \\
&amp;=\frac 1 {p_0 (1-p_0)}-\frac{2}{p_0 (1-p_0)}+\frac{p_0}{p_0^2}+ \frac{1-p_0}{(1-p_0)^2}+0\\
&amp;=-\frac{1}{p_0 (1-p_0)}+\frac{1}{p_0}+ \frac{1}{1-p_0}\\
&amp;= -\frac{1}{p_0 (1-p_0)}+\frac{1-p_0+p_0}{p_0(1-p_0)}\\
&amp;= 0
\end{aligned}
\]</span></p>
<p>Therefore, by Slutsky’s theorem <span class="math inline">\(T_w - T_{LR} \overset P \to 0\)</span>.</p>
<p><span class="math display">\[\begin{aligned}
T_W - T_S &amp;= \frac{n(\hat p- p_0)^2}{\hat p (1-\hat p)} - \frac{n(\hat p- p_0)^2}{p_0 (1-p_0)}\\
&amp;= n \left(\frac{p_0 (1-p_0)(\hat p- p_0)^2-\hat p (1-\hat p)(\hat p- p_0)^2}{\hat p p_0(1-\hat p) (1-p_0)} \right)\\
&amp;= n \left(\frac{[(p_0-p_0^2)-(\hat p-\hat p^2)](\hat p- p_0)^2}{\hat p p_0(1-\hat p) (1-p_0)} \right)\\
&amp;= \left[\sqrt n (\hat p- p_0) \right]^2\left(\frac{p_0 -\hat p + \hat p^2-p_0^2}{\hat p p_0(1-\hat p) (1-p_0)} \right)\\
\text{Note that } &amp;p_0 - \hat p \overset p \to 0 \text{ by WLLN, so}
\left(\frac{p_0 -\hat p + \hat p^2-p_0^2}{\hat p p_0(1-\hat p) (1-p_0)} \right) \overset p \to 0\\
\text{and, }&amp;\left[\sqrt n (\hat p- p_0) \right]^2 \overset d \to \chi^2_{something} \text{ by CLT} \\
\implies T_W - T_S &amp;\overset P \to 0 \text{ by Slutsky's Theorem}
\end{aligned}\]</span></p>
</section>
<section id="section-4" class="level2">
<h2 class="anchored" data-anchor-id="section-4">3.16</h2>
<p><strong>Derive the score statistic <span class="math inline">\(T_S\)</span> in (3.21, p.&nbsp;148)</strong></p>
<p><span class="math display">\[\begin{aligned}
logit(p_{1+2(j-1)}) = \beta_j + \beta_{k+1} ~~&amp;,~~logit(p_{2+2(j-1)}) = \beta_j\\
p_{1+2(j-1)} =  \frac{\exp(\beta_j + \beta_{k+1})}{1+\exp(\beta_j + \beta_{k+1})}~~
&amp;,~~p_{2+2(j-1)} =  \frac{\exp(\beta_j)}{1+\exp(\beta_j)} \\
H_0: \beta_{k+1} = 0
\end{aligned}\]</span></p>
<p><span class="math display">\[\begin{aligned}
\mathcal L(\boldsymbol{\beta}_j, \beta_{k+1}) &amp;= \prod_{j=1}^k \left(p_{1+2(j-1)}\right)^{a_j}
\left(1-p_{1+2(j-1)}\right)^{c_j}
\left(p_{2+2(j-1)}\right)^{b_j}
\left(1-p_{2+2(j-1)}\right)^{d_j} \\
&amp;= \prod_{j=1}^k \left(\frac{\exp(\boldsymbol{\beta}_j + \beta_{k+1})}{1+\exp(\boldsymbol{\beta}_j + \beta_{k+1})}\right)^{a_j}
\left(1-\frac{\exp(\boldsymbol{\beta}_j + \beta_{k+1})}{1+\exp(\boldsymbol{\beta}_j + \beta_{k+1})}\right)^{c_j}\\
&amp;~~~~~~~~~~~~~~~ \times
\left(\frac{\exp(\boldsymbol{\beta}_j)}{1+\exp(\boldsymbol{\beta}_j)}\right)^{b_j}
\left(1-\frac{\exp(\boldsymbol{\beta}_j)}{1+\exp(\boldsymbol{\beta}_j)}\right)^{d_j} \\
&amp;= \prod_{j=1}^k \left(\frac{\exp(\boldsymbol{\beta}_j + \beta_{k+1})}{1+\exp(\boldsymbol{\beta}_j + \beta_{k+1})}\right)^{a_j}
\left(\frac{1}{1+\exp(\boldsymbol{\beta}_j + \beta_{k+1})}\right)^{c_j}\\
&amp;~~~~~~~~~~~~~~~ \times
\left(\frac{\exp(\boldsymbol{\beta}_j)}{1+\exp(\boldsymbol{\beta}_j)}\right)^{b_j}
\left(\frac{1}{1+\exp(\boldsymbol{\beta}_j)}\right)^{d_j} \\
\ell(\boldsymbol{\beta}_j, \beta_{k+1})&amp;= \sum_{j=1}^k
a_j \log \left(\frac{\exp(\boldsymbol{\beta}_j + \beta_{k+1})}{1+\exp(\boldsymbol{\beta}_j + \beta_{k+1})}\right)
-c_j\log\left({1+\exp(\boldsymbol{\beta}_j + \beta_{k+1})}\right)\\
&amp;~~~~~~~~~~~~~~~ +
b_j\log\left(\frac{\exp(\boldsymbol{\beta}_j)}{1+\exp(\boldsymbol{\beta}_j)}\right)
-d_j\log\left({1+\exp(\boldsymbol{\beta}_j)}\right) \\
S(\boldsymbol{\beta}_j, \beta_{k+1})&amp;= \begin{pmatrix}
\left[
a_j \left(1- \frac{\exp(\boldsymbol{\beta}_j + \boldsymbol{\beta}_{k+1})}{1+\exp(\boldsymbol{\beta}_j + \boldsymbol{\beta}_{k+1})}\right)
-c_j\left(\frac{\exp(\boldsymbol{\beta}_j + \boldsymbol{\beta}_{k+1})}{1+\exp(\boldsymbol{\beta}_j + \beta_{k+1})}\right)+
b_j\left(1-\frac{\exp(\boldsymbol{\beta}_j)}{1+\exp(\boldsymbol{\beta}_j)}\right)-
d_j\left(\frac{\exp(\boldsymbol{\beta}_j)}{1+\exp(\boldsymbol{\beta}_j)}\right)\right]_{\substack{j^{th}~ entry~ of \\ k x 1 ~vector}} \\
\sum_{j=1}^k
a_j \left(1- \frac{\exp(\boldsymbol{\beta}_j + \boldsymbol{\beta}_{k+1})}{1+\exp(\boldsymbol{\beta}_j + \boldsymbol{\beta}_{k+1})}\right)
-c_j\left(\frac{\exp(\boldsymbol{\beta}_j + \boldsymbol{\beta}_{k+1})}{1+\exp(\boldsymbol{\beta}_j + \beta_{k+1})}\right)
\end{pmatrix} \\
&amp;= \begin{pmatrix}
\left[
a_j +b_j  -(a_j + c_j)\left(\frac{\exp(\boldsymbol{\beta}_j + \boldsymbol{\beta}_{k+1})}{1+\exp(\boldsymbol{\beta}_j + \boldsymbol{\beta}_{k+1})}\right)
-(b_j+d_j)\left(\frac{\exp(\boldsymbol{\beta}_j)}{1+\exp(\boldsymbol{\beta}_j)}\right)\right]_{\substack{j^{th}~ entry~ of \\ k x 1 ~vector}} \\
\sum_{j=1}^k
a_j-(a_j+c_j)\left(\frac{\exp(\boldsymbol{\beta}_j + \boldsymbol{\beta}_{k+1})}{1+\exp(\boldsymbol{\beta}_j + \beta_{k+1})}\right)
\end{pmatrix} \\
&amp;= \begin{pmatrix}
\left[n_{1j}  -m_{1j}\left(\frac{\exp(\boldsymbol{\beta}_j + \boldsymbol{\beta}_{k+1})}{1+\exp(\boldsymbol{\beta}_j + \boldsymbol{\beta}_{k+1})}\right)
-m_{2j}\left(\frac{\exp(\boldsymbol{\beta}_j)}{1+\exp(\boldsymbol{\beta}_j)}\right) \right]_{\substack{j^{th}~ entry~ of \\ k x 1 ~vector}} \\
\sum_{j=1}^k
a_j-m_{1j}\left(\frac{\exp(\boldsymbol{\beta}_j + \boldsymbol{\beta}_{k+1})}{1+\exp(\boldsymbol{\beta}_j + \beta_{k+1})}\right)
\end{pmatrix}
\end{aligned}\]</span></p>
<p><span class="math display">\[\begin{aligned}
I_T (\boldsymbol{\beta}_j, \beta_{k+1} ) &amp;= - \begin{pmatrix}
diag \left\{-m_{1j}\left(\frac{\exp(\boldsymbol{\beta}_j + \boldsymbol{\beta}_{k+1})}{(1+\exp(\boldsymbol{\beta}_j + \boldsymbol{\beta}_{k+1}))^2}\right)-m_{2j}\left(\frac{\exp(\boldsymbol{\beta}_j)}{(1+\exp(\boldsymbol{\beta}_j))^2}\right)\right\}_{k\times k}
&amp;  \left\{-m_{1j}\left(\frac{\exp(\boldsymbol{\beta}_j + \boldsymbol{\beta}_{k+1})}{(1+\exp(\boldsymbol{\beta}_j + \boldsymbol{\beta}_{k+1}))^2}\right)\right\}_{k\times 1}\\
\left\{-m_{1j}\left(\frac{\exp(\boldsymbol{\beta}_j + \boldsymbol{\beta}_{k+1})}{(1+\exp(\boldsymbol{\beta}_j + \boldsymbol{\beta}_{k+1}))^2}\right)\right\}_{1\times k}
&amp; \left\{\sum_{j=1}^k
-m_{1j}\left(\frac{\exp(\boldsymbol{\beta}_j + \boldsymbol{\beta}_{k+1})}{(1+\exp(\boldsymbol{\beta}_j + \beta_{k+1}))^2}\right) \right\}_{1\times 1}
\end{pmatrix}
\end{aligned}\]</span></p>
<p>Note, under the restricted MLE, <span class="math inline">\(\beta_{k+1} = 0\)</span> implies <span class="math display">\[ \begin{aligned}
p_j&amp;=\frac{\exp(\boldsymbol{\beta}_j )}{(1+\exp(\boldsymbol{\beta}_j)}= \frac{b_{j}}{c_j}= \frac{n_{1j}}{t_j}\\
1-p_j&amp;= \frac{n_{2j}}{t_j} = 1-\frac{\exp(\boldsymbol{\beta}_j )}{(1+\exp(\boldsymbol{\beta}_j)}=\frac{1}{(1+\exp(\boldsymbol{\beta}_j)}\\
\implies p_j(1-p_j) &amp;= \frac{n_{1j}n_{2j}}{t_j^2}
= \frac{\exp(\boldsymbol{\beta}_j)}{(1+\exp(\boldsymbol{\beta}_j))^2}
\end{aligned}\]</span></p>
<p>Thus, <span class="math display">\[\begin{aligned}
\overset \sim I_T (\boldsymbol{\beta}_j, \beta_{k+1} ) &amp;= \begin{pmatrix}
diag \left\{m_{1j}\left(\frac{\exp(\boldsymbol{\beta}_j)}{(1+\exp(\boldsymbol{\beta}_j))^2}\right)+m_{2j}\left(\frac{\exp(\boldsymbol{\beta}_j)}{(1+\exp(\boldsymbol{\beta}_j))^2}\right)\right\}_{k\times k}
&amp;  \left\{m_{1j}\left(\frac{\exp(\boldsymbol{\beta}_j)}{(1+\exp(\boldsymbol{\beta}_j))^2}\right)\right\}_{k\times 1}\\
\left\{m_{1j}\left(\frac{\exp(\boldsymbol{\beta}_j )}{(1+\exp(\boldsymbol{\beta}_j ))^2}\right)\right\}_{1\times k}
&amp; \left\{\sum_{j=1}^k
m_{1j}\left(\frac{\exp(\boldsymbol{\beta}_j )}{(1+\exp(\boldsymbol{\beta}_j))^2}\right) \right\}_{1\times 1}
\end{pmatrix} \\
&amp;= \begin{pmatrix}
diag\left\{\frac{(m_{1j}+ m_{2j})n_{1j}n_{2j}}{t_j^2} \right\}_{k\times k}
&amp;  \left\{m_{1j}\left(\frac{n_{1j}n_{2j}}{t_j^2} \right)\right\}_{k\times 1}\\
\left\{m_{1j}\left(\frac{n_{1j}n_{2j}}{t_j^2} \right)\right\}_{1\times k}
&amp; \left\{\sum_{j=1}^k
m_{1j}\left(\frac{n_{1j}n_{2j}}{t_j^2} \right) \right\}_{1\times 1}
\end{pmatrix} \\
&amp;= \begin{pmatrix}
diag\left\{\frac{t_jn_{1j}n_{2j}}{t_j^2} \right\}_{k\times k}
&amp;  \left\{m_{1j}\left(\frac{n_{1j}n_{2j}}{t_j^2} \right)\right\}_{k\times 1}\\
\left\{m_{1j}\left(\frac{n_{1j}n_{2j}}{t_j^2} \right)\right\}_{1\times k}
&amp; \left\{\sum_{j=1}^k
m_{1j}\left(\frac{n_{1j}n_{2j}}{t_j^2} \right) \right\}_{1\times 1}
\end{pmatrix} \\
\implies \overset \sim I_{T,22}^{-1} &amp;= [\overset \sim I_{T,22} -\overset \sim I_{T,21} \overset \sim I_{T,11}^{-1} \overset \sim I_{T,12} ]^{-1} \\
&amp;= \left(\sum_{j=1}^k
\frac{m_{1j}n_{1j}n_{2j}}{t_j^2} - \left(\frac{m_{1j}n_{1j}n_{2j}}{t_j^2}\right)^2\frac{t_j}{n_{1j}n_{2j}}\right)^{-1}\\
&amp;= \left(\sum_{j=1}^k
\frac{m_{1j}t_jn_{1j}^2n_{2j}^2-m_{1j}^2n_{1j}^2n_{2j}^2}{t_j^3n_{1j}n_{2j}}\right)^{-1}\\
&amp;= \left(\sum_{j=1}^k
\frac{m_{1j}(t_j-m_{1j})n_{1j}n_{2j}}{t_j^3}\right)^{-1}\\
&amp;=\frac{1}{\sum_{j=1}^km_{1j}m_{2j}n_{1j}n_{2j}/t_j^3}\\
\end{aligned}
\]</span></p>
<p>Now, to compute the score under the null hypothesis, <span class="math display">\[\begin{aligned}
\overset \sim S(\beta_j, \beta_{k+1})&amp;= \begin{pmatrix}
\left[n_{1j}  -m_{1j}\left(\frac{\exp(\boldsymbol{\beta}_j)}{1+\exp(\boldsymbol{\beta}_j)}\right)
-m_{2j}\left(\frac{\exp(\boldsymbol{\beta}_j)}{1+\exp(\boldsymbol{\beta}_j)}\right) \right]_{k \times 1} \\
\sum_{j=1}^k
a_j-m_{1j}\left(\frac{\exp(\boldsymbol{\beta}_j)}{1+\exp(\boldsymbol{\beta}_j)}\right)
\end{pmatrix} \\
&amp;= \begin{pmatrix}
\left[n_{1j}  -m_{1j}\left(\frac{n_{1j}}{t_j}\right)
-m_{2j}\left(\frac{n_{1j}}{t_j}\right) \right]_{k \times 1} \\
\sum_{j=1}^k
a_j-m_{1j}\left(\frac{n_{1j}}{t_j}\right)
\end{pmatrix} \\
&amp;= \begin{pmatrix}
\left[n_{1j}  -m_{1j}\left(\frac{n_{1j}}{t_j}\right)
-m_{2j}\left(\frac{n_{1j}}{t_j}\right) \right]_{k \times 1} \\
\sum_{j=1}^k a_j-m_{1j}\left(\frac{n_{1j}}{t_j}\right)
\end{pmatrix} \\
&amp;= \begin{pmatrix}0 \\
\sum_{j=1}^k a_j-m_{1j}\left(\frac{n_{1j}}{t_j}\right) \end{pmatrix} \\
\implies \overset \sim S(\beta_j, \beta_{k+1})^T \overset \sim S(\beta_j, \beta_{k+1})&amp;=
\left[\sum_{j=1}^k a_j-m_{1j}\left(\frac{n_{1j}}{t_j}\right)\right]^2
\end{aligned}\]</span></p>
<p>And the score statistic follows (matching Wikipedia, not the book <strong>OUR CLASS CONCLUDED TEXTBOOK HAS ERROR FROM A PAPER THAT HAD A TYPO</strong>):</p>
<p><span class="math display">\[\begin{aligned}
T_S &amp;= \overset \sim S(\beta_j, \beta_{k+1})^T [\overset \sim I_{T,22} -\overset \sim I_{T,21} \overset \sim I_{T,11}^{-1} \overset \sim I_{T,12} ]^{-1}\overset \sim S(\beta_j, \beta_{k+1})\\
&amp;=\frac{\left[\sum_{j=1}^k a_j-m_{1j}n_{1j}/t_j\right]^2}{\sum_{j=1}^km_{1j}m_{2j}n_{1j}n_{2j}/t_j^3}
\end{aligned}\]</span></p>
</section>
<section id="section-5" class="level2">
<h2 class="anchored" data-anchor-id="section-5">3.18</h2>
<p>Consider having two independent iid samples, the first with a <span class="math inline">\(normal(\mu_1,1)\)</span> distribution and sample size <span class="math inline">\(n_1\)</span>, the second with a <span class="math inline">\(normal(\mu_2,1)\)</span> distribution and sample size <span class="math inline">\(n_2\)</span>. For <span class="math inline">\(H_0: \mu_1= \mu_2\)</span> versus <span class="math inline">\(H_a: \mu_1 &lt; \mu_2\)</span>, find <span class="math inline">\(T_{LR}\)</span> and the testing procedure at <span class="math inline">\(\alpha = 0.05\)</span>.</p>
<p>Solution:</p>
<p>Note that under <span class="math inline">\(H_a\)</span> the maximum likelihood estimators are the usual ones if <span class="math inline">\(\bar Y_1 \leq \bar Y_2\)</span>, but <span class="math inline">\(\hat \mu_1 = \hat \mu_2 = (n_1 \bar Y_1 +n_2 \bar Y _2)/(n_1+n_2)\)</span> if <span class="math inline">\(\bar Y_1 &gt; \bar Y_2\)</span>. Also, note that <span class="math inline">\(P(2,2) = 1/2\)</span> in (3.23, p.&nbsp;152) for this case since the probability is 1/2 that the restricted estimators are the usual sample means with <span class="math inline">\(l=2\)</span> distinct values.</p>
<p><span class="math display">\[\begin{aligned}
\mathcal L(\mu_1,\mu_2) &amp;= \prod_{i=1}^{n_1}\frac{1}{\sqrt{2 \pi}} e ^{-\frac 1 2 (y_{i1}- \mu_1)^2}\prod_{j=1}^{n_2}\frac{1}{\sqrt{2 \pi}} e ^{-\frac 1 2 (y_{j2}- \mu_2)^2} \\
\ell(\mu_1,\mu_2) &amp;= C -\frac 1 2\sum_{i=1}^{n_1} (y_{i1}- \mu_1)^2-\frac 1 2\sum_{j=1}^{n_2} (y_{j2}- \mu_2)^2\\
T_{LR} &amp;= -2 (\ell (\hat \theta_{RMLE})-\ell (\hat \theta_{MLE})) \\
&amp;=\begin{cases} -2 \bigg(\left[-\frac 1 2\sum_{i=1}^{n_1} (y_{i1}- \bar y_1)^2-\frac 1 2\sum_{j=1}^{n_2} (y_{j2}- \bar y_2)^2\right] \\
~~~~~~~~~~~~~~-\left[-\frac 1 2\sum_{i=1}^{n_1} (y_{i1}- \bar y_1)^2-\frac 1 2\sum_{j=1}^{n_2} (y_{j2}- \bar y_2)^2\right] \bigg), &amp; \bar Y_1 \leq \bar Y_2\\
-2 \bigg(\left[-\frac 1 2\sum_{i=1}^{n_1} \left(y_{i1}-  \frac{(n_1 \bar Y_1 +n_2 \bar Y _2)}{(n_1+n_2)}\right)^2-\frac 1 2\sum_{j=1}^{n_2} \left(y_{j2}- \frac{(n_1 \bar Y_1 +n_2 \bar Y _2)}{(n_1+n_2)}\right)^2\right]\\
~~~~~~~~~~~~~~-\left[-\frac 1 2\sum_{i=1}^{n_1} y_{i1}- \bar y_1)^2-\frac 1 2\sum_{j=1}^{n_2} (y_{j2}- \bar y_2)^2\right] \bigg) , &amp;\bar Y_1 &gt; \bar Y_2 \end{cases} \\
&amp;=\begin{cases} 0, &amp; \bar Y_1 \leq \bar Y_2\\
\sum_{i=1}^{n_1} \left(y_{i1}-  \frac{n_1 \bar Y_1 +n_2 \bar Y _2}{n_1+n_2}\right)^2+\sum_{j=1}^{n_2} \left(y_{j2}- \frac{n_1 \bar Y_1 +n_2 \bar Y _2}{n_1+n_2}\right)^2\\
~~~~~~~~~~~~~~-\sum_{i=1}^{n_1} (y_{i1}^2- 2 y_{i1}\bar y_1 + \bar y_1^2)-\sum_{j=1}^{n_2} (y_{j2}^2-2y_{j2}\bar Y_2 +\bar Y_2^2) , &amp;\bar Y_1 &gt; \bar Y_2 \end{cases}
\end{aligned}\]</span> <span class="math display">\[\begin{aligned}
&amp;=\begin{cases} 0, &amp; \bar Y_1 \leq \bar Y_2\\
\sum_{i=1}^{n_1} y_{i1}^2-  2n_1\bar Y_1 \frac{n_1 \bar Y_1 +n_2 \bar Y _2}{n_1+n_2}+n_1\left(\frac{n_1 \bar Y_1 +n_2 \bar Y _2}{n_1+n_2}\right)^2+\sum_{j=1}^{n_2} y_{j2}^2-2n_2 \bar Y_2 \frac{n_1 \bar Y_1 +n_2 \bar Y _2}{n_1+n_2} + n_2 \left(\frac{n_1 \bar Y_1 +n_2 \bar Y _2}{n_1+n_2}\right)^2\\
~~~~~~~~~~~~~~-\sum_{i=1}^{n_1} y_{i1}^2 + 2 n_1 \bar Y_1^2 - n_1\bar Y_1^2-\sum_{j=1}^{n_2} y_{j2}^2+2n_2\bar Y_2^2 -n_2\bar Y_2^2 , &amp;\bar Y_1 &gt; \bar Y_2 \end{cases} \\
&amp;=\begin{cases} 0, &amp; \bar Y_1 \leq \bar Y_2\\
-  2\frac{(n_1 \bar Y_1 +n_2 \bar Y _2)^2}{n_1+n_2}+(n_1+n_2)\left(\frac{n_1 \bar Y_1 +n_2 \bar Y _2}{n_1+n_2}\right)^2+  n_1 \bar Y_1^2 +n_2\bar Y_2^2 , &amp;\bar Y_1 &gt; \bar Y_2 \end{cases} \\
&amp;=\begin{cases} 0, &amp; \bar Y_1 \leq \bar Y_2\\
n_1 \bar Y_1^2 +n_2\bar Y_2^2 -  \frac{(n_1 \bar Y_1 +n_2 \bar Y _2)^2}{n_1+n_2}, &amp;\bar Y_1 &gt; \bar Y_2
\end{cases}\\
&amp;=\begin{cases} 0, &amp; \bar Y_1 \leq \bar Y_2\\
\frac{(n_1+n_2)(n_1 \bar Y_1^2 +n_2\bar Y_2^2) -(n_1 \bar Y_1 +n_2 \bar Y _2)^2}{n_1+n_2}, &amp;\bar Y_1 &gt; \bar Y_2 \end{cases} \\
&amp;=\begin{cases} 0, &amp; \bar Y_1 \leq \bar Y_2\\
\frac{(n_1^2 \bar Y_1^2 + n_1n_2 \bar Y_1^2 +n_1n_2 \bar Y_2^2 +n_2^2\bar Y_2^2) -(n_1^2 \bar Y_1^2 +2n_1n_2 \bar Y_1 \bar Y_2 +n_2^2 \bar Y _2^2)}{n_1+n_2}, &amp;\bar Y_1 &gt; \bar Y_2 \end{cases} \\
  &amp;=\begin{cases} 0, &amp; \bar Y_1 \leq \bar Y_2\\
\left(\frac{n_1n_2}{n_1+n_2}\right)(\bar Y_1^2 -2 \bar Y_1 \bar Y_2 + \bar Y_2^2), &amp;\bar Y_1 &gt; \bar Y_2 \end{cases} \\
  &amp;=\begin{cases} 0, &amp; \bar Y_1 \leq \bar Y_2\\
\left(\frac{n_1n_2}{n_1+n_2}\right)(\bar Y_1-\bar Y_2)^2, &amp;\bar Y_1 &gt; \bar Y_2 \end{cases}
\end{aligned}\]</span></p>
<p>From 3.6.1a (p.&nbsp;151), the <span class="math inline">\(T_{LR}\)</span> follows a non-chi-square distribution, <span class="math inline">\(\bar \chi^2_{k=2}\)</span>. Note, that the following page states <span class="math inline">\(P(\bar \chi^2_{k=2} \geq C) = \frac 1 2 I(C=0) + \frac 1 2P(\chi^2_{k=2} \geq C)\)</span></p>
<p>So I need to find the value <span class="math inline">\(C\)</span> such that:</p>
<p><span class="math display">\[.05 = \alpha =P(\bar \chi^2_{k=2} \geq C) = \frac 1 2 I(C=0) + \frac 1 2P(\chi^2_{2} \geq C)\]</span> Note that <span class="math inline">\(C \neq 0\)</span>, because if it were, we would get <span class="math inline">\(1= P(\bar \chi^2_{k=2} \geq C)\)</span>.</p>
<p>Thus, I am left with, <span class="math display">\[ \begin{aligned}
.05 &amp;=  \frac 1 2P(\chi^2_{2} \geq C) \\
\implies .1 &amp;= P(\chi^2_{2} \geq C) \\
\implies C &amp;= 4.60517 &amp;\text{by r command qchisq(.1, df = 2, lower.tail = F)}
\end{aligned}\]</span></p>
<p>Therefore the testing procedure is to reject <span class="math inline">\(H_0\)</span> if <span class="math inline">\(\bar Y_1&gt; Y_2\)</span> AND <span class="math inline">\(\left(\frac{n_1n_2}{n_1+n_2}\right)(\bar Y_1-\bar Y_2)^2 &gt; 4.60517\)</span>.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/ch2.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">Chapter 2: Likelihood Construction and Estimation</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/ch5.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-title">Chapter 5: Large Sample Theory: The Basics</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>